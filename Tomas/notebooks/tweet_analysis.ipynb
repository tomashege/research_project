{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "#from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import collections\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import datetime\n",
    "import matplotlib.dates as mdates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input tweets from pickle file (They have been cleaned allready)\n",
    "tweets = pd.read_pickle(\"/Users/tomashegewisch/Desktop/all_6_months.pkl\")\n",
    "d1 = \"2020-03-01\"\n",
    "d2 = \"2020-08-31\"\n",
    "def get_date_range_for_tweet(date):\n",
    "    date_1 = datetime.datetime.strptime(d1,'%Y-%m-%d')\n",
    "    date_2 = datetime.datetime.strptime(d2,'%Y-%m-%d')\n",
    "    date = date.to_pydatetime().strftime(\"%Y-%m-%d\")\n",
    "    date = datetime.datetime.strptime(date,'%Y-%m-%d')\n",
    "    if date >= date_1 and date <= date_2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Remove tweets that are out of the date range \n",
    "tweets = tweets[tweets['date'].apply(lambda x : get_date_range_for_tweet(x)) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from all the words that have been tokenised\n",
    "word_list = [] \n",
    "for i in tweets['tokenised']:\n",
    "    for j in i:\n",
    "        if j != \"amp\":\n",
    "            word_list.append(j)\n",
    "word_list = pd.DataFrame(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a Sentimnet value for each tweet.\n",
    "def get_sent(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "tweets['senti_values'] = tweets['tweet_clean'].apply(lambda x : get_sent(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart showing Sentimnet for the top 10 most common words.\n",
    "word_list_counter = Counter(word_list[0])\n",
    "def get_sent_for_top_words(text, lookout_word):\n",
    "    if lookout_word not in text:\n",
    "        return None\n",
    "    else:\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "\n",
    "for i in word_list_counter.most_common(10):\n",
    "    tweet_senti_values = tweets['tweet_clean'].apply(lambda x : get_sent_for_top_words(x, i[0]))\n",
    "    tweet_senti_values = tweet_senti_values.dropna(axis=0, inplace=False, how=None)\n",
    "    #tweet_senti_values.hist()\n",
    "    plt.hist(tweet_senti_values)\n",
    "    plt.title('Sentiment around the word: ' + i[0])\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.ylabel('Count')\n",
    "    plt.savefig(\"/Users/tomashegewisch/research_project/Tomas/charts/barchat/barchart_Sentiment_\"+i[0]+\".png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split positive and negitive tweets into two diffrent data frame columes.\n",
    "def get_value_positive(x):\n",
    "    if x > 0.0:\n",
    "        return x\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_value_negitive(x):\n",
    "    if x < 0.0:\n",
    "        return x\n",
    "    else:\n",
    "        return None\n",
    "# we have removed the 0 from both.  \n",
    "tweets[\"positve\"] = tweets['senti_values'].apply(get_value_positive)\n",
    "tweets[\"negitive\"] = tweets['senti_values'].apply(get_value_negitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dis\n",
    "positive_date_mean = tweets.groupby('date', as_index=False)['positve'].mean()\n",
    "negitive_date_mean = tweets.groupby('date', as_index=False)['negitive'].mean()\n",
    "display_df_average = positive_date_mean\n",
    "display_df_average['negitive'] = negitive_date_mean['negitive']\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.lineplot(x='Date',\n",
    "             y='Polarity', \n",
    "             hue='Key',\n",
    "             data= pd.melt(display_df_average, ['date']).rename(columns={\"value\": \"Polarity\",\"variable\":\"Key\", \"date\":\"Date\"})\n",
    "            ).set_title(\"Timeline of Sentiment from collected tweetsâ€™ (1 March - 31 August)\").get_figure()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/Users/tomashegewisch/research_project/Tomas/charts/Sentiment_\"+\"Timeline of sentiment from collected tweets.png\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_word(text, kw):\n",
    "    if kw in text:\n",
    "        return True\n",
    "    else:\n",
    "        return \"no\"\n",
    "    \n",
    "# want to find the date range \n",
    "def get_the_date(month_code):\n",
    "    moths_dates = {1:['2020-03-01','2020-03-31',\"March\"],\n",
    "                  2:['2020-04-01','2020-04-30', \"April\"],\n",
    "                  3:['2020-05-01','2020-05-31', \"May\"],\n",
    "                  4:['2020-06-01','2020-06-30', \"June\"],\n",
    "                  5:['2020-07-01','2020-07-31', \"July\"],\n",
    "                  6:['2020-08-01','2020-08-31', \"August\"],\n",
    "                  7:['2020-09-01','2020-09-30', \"September\"],\n",
    "                  8:['2020-10-01','2020-10-31', \"October\"]}\n",
    "    return moths_dates[month_code]\n",
    "\n",
    "# retrunr if the date is not in the rage\n",
    "def get_date_range(date, d1, d2):\n",
    "    date_1 = datetime.datetime.strptime(d1,'%Y-%m-%d')\n",
    "    date_2 = datetime.datetime.strptime(d2,'%Y-%m-%d')\n",
    "    date = date.to_pydatetime().strftime(\"%Y-%m-%d\")\n",
    "    date = datetime.datetime.strptime(date,'%Y-%m-%d')\n",
    "    if date >= date_1 and date <= date_2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# group by date\n",
    "\n",
    "for i in range(1,9):\n",
    "    nedded_dates = get_the_date(i)\n",
    "    for i in word_list_counter.most_common(1):\n",
    "        # select start and end date\n",
    "        # Drop The columes that do not include the key_word\n",
    "        key_word = i[0]\n",
    "        key_word_sentimnet_score_all = tweets[tweets['tweet'].apply(lambda x : get_key_word(x,key_word)) == True]\n",
    "        key_word_sentimnet_score_all = key_word_sentimnet_score_all[key_word_sentimnet_score_all['date'].apply(lambda x : get_date_range(x, nedded_dates[0], nedded_dates[1])) == True]\n",
    "        #Group by\n",
    "        positive_date_mean = key_word_sentimnet_score_all.groupby('date', as_index=False)['positve'].mean()\n",
    "        negitive_date_mean = key_word_sentimnet_score_all.groupby('date', as_index=False)['negitive'].mean()\n",
    "        # ASK RICH ABOUT THIS SECTION OF CODE>>> What it does is adds the prvious value to the NaN sections.\n",
    "        NaN_test = pd.isnull(positive_date_mean)\n",
    "        temp = 0.0 \n",
    "        for i in range(0, len(NaN_test)):\n",
    "            try:\n",
    "                if NaN_test['positve'][i] == True:\n",
    "\n",
    "                    positive_date_mean['positve'][i] = temp\n",
    "                else:\n",
    "                    temp = positive_date_mean['positve'][i]\n",
    "            except:\n",
    "                continue\n",
    "        NaN_test = pd.isnull(negitive_date_mean)\n",
    "        temp = 0.0\n",
    "        for i in range(0, len(NaN_test)):\n",
    "            try:\n",
    "                if NaN_test['negitive'][i] == True:\n",
    "                    negitive_date_mean['negitive'][i] = temp\n",
    "                else:\n",
    "                    temp = negitive_date_mean['negitive'][i]\n",
    "            except:\n",
    "                continue \n",
    "\n",
    "        # Dsiplay The plot.\n",
    "        display_df_average = positive_date_mean\n",
    "        display_df_average['negitive'] = negitive_date_mean['negitive']\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        sns.lineplot(x='Date', y='Polarity', hue='Key', \n",
    "             data=pd.melt(display_df_average, ['date']).rename(columns={\"value\": \"Polarity\",\"variable\":\"Key\", \"date\":\"Date\"})).set_title(\"The Sentiment for \" + str(nedded_dates[2]) + \" of Topic: \"+key_word).get_figure().autofmt_xdate()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"/Users/tomashegewisch/research_project/Tomas/charts/line_sentiment/Sentiment_\"+key_word+\"_\"+str(nedded_dates[2])+\".png\")\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drill down code\n",
    "def drill_down_date_topic(topic_word, date_1, date_2):\n",
    "    key_word = topic_word\n",
    "    nedded_dates = [date_1, date_2]\n",
    "    key_word_sentimnet_score_all = tweets[tweets['tweet'].apply(lambda x : get_key_word(x,key_word)) == True]\n",
    "    key_word_sentimnet_score_all = key_word_sentimnet_score_all[key_word_sentimnet_score_all['date'].apply(lambda x : get_date_range(x, nedded_dates[0], nedded_dates[1])) == True]\n",
    "    positive_date_mean = key_word_sentimnet_score_all.groupby('date', as_index=False)['positve'].mean()\n",
    "    negitive_date_mean = key_word_sentimnet_score_all.groupby('date', as_index=False)['negitive'].mean()\n",
    "    # ASK RICH ABOUT THIS SECTION OF CODE>>> What it does is adds the prvious value to the NaN sections.\n",
    "    NaN_test = pd.isnull(positive_date_mean)\n",
    "    temp = 0.0 \n",
    "    for i in range(0, len(NaN_test)):\n",
    "        try:\n",
    "            if NaN_test['positve'][i] == True:\n",
    "                positive_date_mean['positve'][i] = temp\n",
    "            else:\n",
    "                temp = positive_date_mean['positve'][i]\n",
    "        except:\n",
    "            continue\n",
    "    NaN_test = pd.isnull(negitive_date_mean)\n",
    "    temp = 0.0\n",
    "    for i in range(0, len(NaN_test)):\n",
    "        try:\n",
    "            if NaN_test['negitive'][i] == True:\n",
    "                negitive_date_mean['negitive'][i] = temp\n",
    "            else:\n",
    "                temp = negitive_date_mean['negitive'][i]\n",
    "        except:\n",
    "            continue \n",
    "\n",
    "        # Dsiplay The files.\n",
    "    display_df_average = positive_date_mean\n",
    "    display_df_average['negitive'] = negitive_date_mean['negitive']\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    sns.lineplot(x='Date',\n",
    "                 y='Polarity',\n",
    "                 hue='Key',\n",
    "                 data=pd.melt(display_df_average, \n",
    "                              ['date']).rename(columns={\"value\": \"Polarity\",\"variable\":\"Key\", \"date\":\"Date\"})).set_title(\"The Sentiment for \" + str(nedded_dates) + \" of Topic: \"+key_word).get_figure().autofmt_xdate()\n",
    "    plt.tight_layout()\n",
    "    print(nedded_dates)\n",
    "    plt.show()\n",
    "    #plt.savefig(\"/Users/tomashegewisch/research_project/Tomas/charts/Sentiment_\"+key_word+\"_\"+str(nedded_dates[0])+\"_\"+str(nedded_dates[1])+\".png\")\n",
    "    plt.clf()\n",
    "\n",
    "drill_down_date_topic(\"covid\", '2020-04-09', '2020-04-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency of posting\n",
    "post_feq = tweets.groupby('date', as_index=False).size()\n",
    "post_feq\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.lineplot(x='date',\n",
    "                 y='size',\n",
    "                 data=post_feq).set_title(\"Tweet Frequency\").get_figure().autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(\"/Users/tomashegewisch/research_project/Tomas/charts/Frequency/tweet_frequency.png\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the timeline frequency for popular hastags for the 6 months. \n",
    "def get_time_line_of_hastages(find_word):\n",
    "    def get_if_hastag(htags_list):\n",
    "        for i in htags_list:\n",
    "            if i == find_word[0]:\n",
    "                return True\n",
    "        return False\n",
    "    specific_hastage_tweets = tweets[tweets['hashtags'].apply(lambda x : get_if_hastag(x)) == True]\n",
    "    post_feq = specific_hastage_tweets.groupby('date', as_index=False).size()\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    sns.lineplot(x='date',\n",
    "                 y='size',\n",
    "                 data=post_feq).set_title(\"Frequency for: \"+str(find_word)).get_figure().autofmt_xdate()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(\"/Users/tomashegewisch/research_project/Tomas/charts/Frequency/feq_\"+str(find_word[0])+\".png\")\n",
    "    plt.clf()\n",
    "    \n",
    "list_of_hastages_to_process = ['covid19', \n",
    "'southafrica', \n",
    "'lockdownsa', \n",
    "'cyrilramaphosa', \n",
    "'lockdown', \n",
    "'covid19sa',\n",
    "'coronavirussa',\n",
    "'covid_19', \n",
    "'lockdownsouthafrica',\n",
    "'government']\n",
    "for i in list_of_hastages_to_process:\n",
    "    get_time_line_of_hastages(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the collected tweets on a map\n",
    "places = []\n",
    "for i in tweets['place']:\n",
    "    try:\n",
    "        places.append(i['coordinates'])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "ruh_m = plt.imread('/Users/tomashegewisch/research_project/Tomas/data/map.png')\n",
    "map_points = pd.DataFrame(places)\n",
    "map_points.columns = ['latitude', 'longitude']\n",
    "\n",
    "#Latitude: -28.4793 Longitude: 24.6727.\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,9))\n",
    "ax.scatter(map_points.longitude, map_points.latitude, zorder=1, alpha= 1, c='red', s=10)\n",
    "\n",
    "BBox = ((map_points.longitude.min(),   map_points.longitude.max(),      \n",
    "         map_points.latitude.min(), map_points.latitude.max()))\n",
    "\n",
    "ax.set_title('Tweet map')\n",
    "ax.set_xlim(BBox[0],BBox[1])\n",
    "ax.set_ylim(BBox[2],BBox[3])\n",
    "ax.axis(\"off\") \n",
    "ax.imshow(ruh_m, zorder=0, extent = BBox, aspect= 'equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word Cloud all words... no hash tags .. no mentions\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "hashtags = []\n",
    "# #create a list of hashtages\n",
    "for i in tweets['hashtags']:\n",
    "    for j in i:\n",
    "        hashtags.append(j)\n",
    "        \n",
    "mentions = []\n",
    "for i in tweets['mentions']:\n",
    "    for j in i:\n",
    "        mentions.append(j['screen_name'])\n",
    "\n",
    "x = set(word_list[0].tolist())\n",
    "y = set(hashtags)\n",
    "x.difference_update(y)\n",
    "cleaned_words_no_hashtags = list(x)\n",
    "\n",
    "x2 = set(cleaned_words_no_hashtags)\n",
    "y2 = set(mentions)\n",
    "x2.difference_update(y2)\n",
    "cleaned_words_no_hashtags = list(x2)\n",
    "\n",
    "text=\" \".join(cleaned_words_no_hashtags)\n",
    "\n",
    "wordcloud = WordCloud(width = 1000, height = 800, \n",
    "                background_color ='white',  \n",
    "                min_font_size = 10).generate(text)\n",
    "\n",
    "#plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word cloud with negitive sentimnet tweets.\n",
    "negitive_tweets_words_list = []\n",
    "\n",
    "for i in range(0, len(tweets)):\n",
    "    try:\n",
    "        if tweets['senti_values'][i] < 0:\n",
    "            for j in tweets['tokenised'][i]:\n",
    "                negitive_tweets_words_list.append(j)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "x = set(negitive_tweets_words_list)\n",
    "y = set(hashtags)\n",
    "x.difference_update(y)\n",
    "negitve_words_no_hashtags = list(x)\n",
    "\n",
    "#cleaned_words_no_hashtags_negitive\n",
    "\n",
    "text = \" \".join(negitve_words_no_hashtags)\n",
    "wordcloud = WordCloud(width = 1000, height = 800, \n",
    "               background_color ='white',  \n",
    "               min_font_size = 12).generate(text)  \n",
    "#plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.title(\"Only Negative tweet's words\", size = 12, color = \"black\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word cloud with negitive positive tweets.\n",
    "positive_tweets_words_list = []\n",
    "\n",
    "for i in range(0, len(tweets)):\n",
    "    try:\n",
    "        if tweets['senti_values'][i] > 0:\n",
    "            for j in tweets['tokenised'][i]:\n",
    "                negitive_tweets_words_list.append(j)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "x = set(positive_tweets_words_list)\n",
    "y = set(hashtags)\n",
    "x.difference_update(y)\n",
    "\n",
    "\n",
    "text = \" \".join(list(x))\n",
    "wordcloud = WordCloud(width = 1000, height = 800, \n",
    "               background_color ='white',  \n",
    "               min_font_size = 12).generate(text)  \n",
    "#plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.title(\"Only positive tweet's words\", size = 12, color = \"black\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
